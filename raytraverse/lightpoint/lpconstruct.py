# -*- coding: utf-8 -*-
# Copyright (c) 2020 Stephen Wasilewski, HSLU and EPFL
# =======================================================================
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.
# =======================================================================
"""functions for generating new lightpoints from existing"""
import numpy as np
from raytraverse.evaluate import FieldMetric
from sklearn.cluster import AgglomerativeClustering, Birch

from raytraverse import translate
from raytraverse.lightpoint.lightpointkd import LightPointKD
from raytraverse.lightpoint.sunpointkd import SunPointKD


def add_sources(lf1, lf2, src=None, calcomega=True, write=True):
    """add light points of distinct sources together
    results in a new lightpoint with srcn=srcn1+srcn2 and
    vector size=vecsize1+vecsize2

    Parameters
    ----------
    lf1: raytraverse.lightpoint.LightPointKD
        this lightpoint sets all parameters of output
    lf2: raytraverse.lightpoint.LightPointKD
    src: str, optional
        if None (default), src is "{lf1.src}_{lf2.src}"
    calcomega: bool, optional
        passed to LightPointKD constructor
    write: bool, optional
        passed to LightPointKD constructor
    Returns
    -------
    raytraverse.lightpoint.LightPointKD
    """
    vecs = np.concatenate((lf1.vec, lf2.vec), axis=0)
    i, d = lf1.query_ray(lf2.vec)
    lum1at2 = np.concatenate((lf1.lum, lf1.lum[i]), axis=0)
    i, d = lf2.query_ray(lf1.vec)
    lum2at1 = np.concatenate((lf2.lum[i], lf2.lum), axis=0)
    lums = np.concatenate((lum1at2, lum2at1), axis=1)
    if src is None:
        src = f"{lf1.src}_{lf2.src}"
    kwargs = dict(vec=vecs, lum=lums, vm=lf1.vm, pt=lf1.pt, posidx=lf1.posidx,
                  src=src, srcn=lf1.srcn + lf2.srcn, calcomega=calcomega,
                  write=write)
    if hasattr(lf1, "sunview") and hasattr(lf1, "sunpos"):
        sunview = lf1.sunview
        sun = lf1.sunpos
    elif hasattr(lf2, "sunview") and hasattr(lf2, "sunpos"):
        sunview = lf2.sunview
        sun = lf2.sunpos
    else:
        sunview = None
        sun = None
    if sunview is None:
        lf_out = LightPointKD(lf1.scene, **kwargs)
    else:
        lf_out = SunPointKD(lf1.scene, sun=sun, sunview=sunview,
                            filterview=False, **kwargs)
    return lf_out


def cluster_fit(clust, wv):
    """take a sklearn.cluster instance and fit a set of vectors, returns labels
    and slices for grouping arrays with same first dimension as wv.

    Parameters
    ----------
    clust:
        initialized skleaern.cluster Class with fit() method
    wv: np.array
        2D vector to cluster: (n_samples, n_features)

    Returns
    -------
    labels: np.array
        (n_samples,) array of ints
    slices: list
        length = len(np.unique(labels))
        list of arrays for indexing cluster groups

    """
    clust.fit(wv)
    lsort = np.argsort(clust.labels_)
    ul, sidx = np.unique(clust.labels_[lsort], return_index=True)
    slices = np.array_split(lsort, sidx[1:])
    return clust.labels_, slices


def cluster_birch(lf, dist=0.19603428, lweight=4):
    """perform cluster fit with the Birch algoritm on a 4D vector
    using lf.vec and uniform weighted lf.lum

    Parameters
    ----------
    lf: raytraverse.lightpoint.LightPointKD
        the lightpoint to cluster
    dist: float, optional
        sub-cluster radius (the threshold parameter of sklearn.cluster.Birch,
        default = translate.theta2chord(np.pi/16)
    lweight: float, optional
        coefficient for min-max normalized luminances, bigger values weight
        luminance more strongly compared to vector direction, meaning with
        higher numbers clusters will have less variance in luminance.

    Returns
    -------
    labels: np.array
        (n_samples,) array of ints
    slices: list
        length = len(np.unique(labels))
        list of arrays for indexing cluster groups

    """
    lum = lf.apply_coef(1).ravel()
    bound = np.percentile(lum, (0, 100))
    scale = bound[1] - bound[0]
    # ldist = l * 8/ scale
    ldist = (lum - bound[0]) * lweight / scale
    wv = np.hstack((lf.vec, ldist[:, None]))
    clust = Birch(threshold=dist, n_clusters=None)
    return cluster_fit(clust, wv)


def agglom_sources(vec, oga, lum, lthreshold, dthreshold=0.25):
    """group vector/omega/lum data according to slices generated by clustering

        Parameters
        ----------
        vec: np.array
            shape (N, 3) normalized direction vectors for each ray
        oga: np.array
            shape (N,) solid angles of each ray
        lum: np.array
            shape (N,) or (N, nsrc) luminance of each ray
        lthreshold: float
            threshold for source detection
        dthreshold: float
            distance_threshold for AgglomerativeClustering with 'average'
            linkage

        Returns
        -------
        sources: np.array
            shape (X, 4 + nsrc), reduced source rays
        background: np.array
            shape (Y, 4 + nsrc), un-reduced background rays
        """
    lum = np.reshape(lum, (vec.shape[0], -1))
    mask = np.any(lum > lthreshold, 1)
    print(lthreshold, np.max(lum), np.sum(mask))
    if np.sum(mask) > 1:
        clust = AgglomerativeClustering(n_clusters=None, linkage='average',
                                        distance_threshold=dthreshold)
        labels, slices = cluster_fit(clust, vec[mask])
        sources = reduce(vec[mask], oga[mask], lum[mask], slices)
    else:
        sources = np.hstack((vec[mask], oga[mask, None], lum[mask]))
    mask = np.logical_not(mask)
    background = np.hstack((vec[mask], oga[mask, None], lum[mask]))
    return sources, background


def reduce(vec, oga, lum, slices):
    """group vector/omega/lum data according to slices generated by clustering

    Parameters
    ----------
    vec: np.array
        shape (N, 3) normalized direction vectors for each ray
    oga: np.array
        shape (N,) solid angles of each ray
    lum: np.array
        shape (N,) or (N, nsrc) luminance of each ray
    slices: list
        length = len(np.unique(labels))
        list of index arrays for each cluster label

    Returns
    -------
    reduced: np.array
        shape (len(slices), 4 + nsrc), reduced ray set
    """
    v2 = []
    o2 = []
    l2 = []
    lum = np.reshape(lum, (vec.shape[0], -1))
    for s in slices:
        v = np.average(vec[s], 0, weights=oga[s])
        mag = np.linalg.norm(v)
        v2.append(v / mag)
        o2.append(np.sum(oga[s]))
        l2.append(np.average(lum[s], 0, weights=oga[s]))
    return np.hstack((v2, np.array(o2)[:, None], np.array(l2)))


def consolidate(lf, src=None, write=False, dist1=0.19603428, lweight=4,
                secondary=False, dist2=0.25, lthreshold=0.3):
    """A lossy compression based on 2 stages of clustering. In the first, rays
    are clustered using the birch algoritm on a 4D vector including (x,y,z,lum)
    where lum is the sum of contributions from all sources in the LightPoint.
    In the optional second stage (activated with secondary=True) sources are
    further grouped through agglomerative cluster using an average linkage. this
    is to help with source indentification/matching between LightPoints, but can
    introduce significant errors to computing non energy conserving metrics in
    cases where the applied sky vectors have large relative differences between
    adjacent patches (> 1.5:1) or if the variance in peak luminance above the
    lthreshold parameter is significant. These include cases where nearby
    transmitting materials is varied (example: a trans upper above a clear
    lower), or lthreshold is set too low. For this reason, it is better to use
    single stage compression for metric computation and only do glare source
    grouping for interpolation between LightPoints.

    Parameters
    ----------
    lf: raytraverse.lightpoint.LightPointKD
    src: str, optional
        new name for src passed to LightPointKD constructor
    write: bool, optional
        save lightpoint to disk
    dist1: float, optional
        translate.theta2chord(np.pi/16), primary clustering distance
        using the birch algorithm, for lossy compression of lf. this is the
        maximum radius of a cluster, preserving important directional
        information. clustering acts on ray direction and luminance, with
        weight of luminance dimension controlled by the lweight parameter.
    lweight: float, optional
        coefficient for min-max normalized luminances used in primary
        compression clustering, bigger values weight luminance more strongly
        compared to vector direction, meaning with higher numbers clusters
        will have less variance in luminance.
    secondary: bool, optional
        switch to control secondary source clustering (default=False)
    dist2: float, optional
        secondary clustering distance using the agglomerative clustering with
        an average linkage. this is for source clustering. If this distance is
        larger than the src area represented by the
    lthreshold: float
        threshold for source detection in secondary clustering, if no luminances
        for ray direction are above threshold, ray is considered background and
        is not clustered. Note that secondary clustering only operates on ray
        direction, so it is important that this threshold isolates

    Returns
    -------
    raytraverse.lightpoint.LightPointKD

    """
    labels, slices = cluster_birch(lf, dist1, lweight)
    step1 = reduce(lf.vec, lf.omega, lf.lum, slices)
    ovec = step1[:, 0:3]
    ooga = step1[:, 3]
    olum = step1[:, 4:]
    if secondary:
        step2 = agglom_sources(ovec, ooga, olum, lthreshold, dist2)
        step2 = np.concatenate(step2, 0)
        print(step1.shape, step2.shape)
        ovec = step2[:, 0:3]
        ooga = step2[:, 3]
        olum = step2[:, 4:]
    if src is None:
        src = f"{lf.src}_compressed"
    return LightPointKD(lf.scene, ovec, olum, vm=lf.vm, pt=lf.pt,
                        posidx=lf.posidx, src=src, srcn=lf.srcn, omega=ooga,
                        write=write)
